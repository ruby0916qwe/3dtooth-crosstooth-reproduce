import os
import subprocess
import sys
from pathlib import Path

def batch_predict():
    """
    ä½¿ç”¨test_for_predictä¸­çš„æ•°æ®æ¥è¿è¡Œpredict.py
    å¯¹æ¯ä¸ªè¾“å‡ºç»“æœç”Ÿæˆå¯¹åº”çš„maskæ–‡ä»¶
    """
    # æºæ–‡ä»¶å¤¹å’Œç›®æ ‡æ–‡ä»¶å¤¹
    source_dir = "test_for_predict"
    target_dir = "test_predict_results"
    
    # æ£€æŸ¥æºæ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
    if not os.path.exists(source_dir):
        print(f"é”™è¯¯: æºæ–‡ä»¶å¤¹ {source_dir} ä¸å­˜åœ¨")
        return
    
    # åˆ›å»ºç›®æ ‡æ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if not os.path.exists(target_dir):
        os.makedirs(target_dir)
        print(f"åˆ›å»ºæ–‡ä»¶å¤¹: {target_dir}")
    
    # è·å–æ‰€æœ‰plyæ–‡ä»¶
    ply_files = [f for f in os.listdir(source_dir) if f.endswith('.ply')]
    
    if not ply_files:
        print(f"åœ¨ {source_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°.plyæ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ° {len(ply_files)} ä¸ª.plyæ–‡ä»¶ï¼Œå¼€å§‹æ‰¹é‡é¢„æµ‹...")
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    try:
        import torch
        cuda_available = torch.cuda.is_available()
        print(f"CUDAå¯ç”¨æ€§: {'æ˜¯' if cuda_available else 'å¦'}")
        if cuda_available:
            print(f"GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")
    except ImportError:
        print("è­¦å‘Š: æ— æ³•å¯¼å…¥torchï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
        cuda_available = False
    
    # ç»Ÿè®¡å˜é‡
    success_count = 0
    error_count = 0
    error_files = []
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    for i, ply_file in enumerate(ply_files, 1):
        # æå–æ–‡ä»¶åï¼ˆå»æ‰_for_predict.plyåç¼€ï¼‰
        base_name = ply_file.replace('_for_predict.ply', '')
        
        # æ„å»ºè¾“å‡ºæ–‡ä»¶å
        output_file = f"{base_name}_mask.ply"
        output_path = os.path.join(target_dir, output_file)
        
        # æ„å»ºå®Œæ•´çš„è¾“å…¥æ–‡ä»¶è·¯å¾„
        input_path = os.path.join(source_dir, ply_file)
        
        print(f"[{i}/{len(ply_files)}] é¢„æµ‹: {ply_file} -> {output_file}")
        
        try:
            # è¿è¡Œpredict.py
            # æ ¼å¼: python predict.py --case input.ply --save_path output.ply
            cmd = [
                sys.executable, 'predict.py',
                '--case', input_path,
                '--save_path', output_path,
                '--pretrain_model_path', 'models/PTv1/point_best_model.pth',
                '--num_points', '16000',
                '--sample_points', '16000'
            ]
            
            # æ ¹æ®CUDAå¯ç”¨æ€§è®¾ç½®å‚æ•°
            if cuda_available:
                cmd.extend(['--no_cuda', 'False'])
            else:
                cmd.extend(['--no_cuda', 'True'])
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°5åˆ†é’Ÿ
            
            if result.returncode == 0:
                print(f"  âœ… æˆåŠŸ: {output_file}")
                success_count += 1
            else:
                print(f"  âŒ å¤±è´¥: {ply_file}")
                print(f"     é”™è¯¯ä¿¡æ¯: {result.stderr}")
                error_count += 1
                error_files.append(ply_file)
                
        except subprocess.TimeoutExpired:
            print(f"  â° è¶…æ—¶: {ply_file}")
            error_count += 1
            error_files.append(ply_file)
        except Exception as e:
            print(f"  ğŸ’¥ å¼‚å¸¸: {ply_file} - {str(e)}")
            error_count += 1
            error_files.append(ply_file)
    
    # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡ç»“æœ
    print(f"\n=== æ‰¹é‡é¢„æµ‹å®Œæˆ ===")
    print(f"æ€»æ–‡ä»¶æ•°: {len(ply_files)}")
    print(f"æˆåŠŸé¢„æµ‹: {success_count}")
    print(f"é¢„æµ‹å¤±è´¥: {error_count}")
    print(f"æˆåŠŸç‡: {success_count/len(ply_files)*100:.1f}%")
    
    if error_files:
        print(f"\nå¤±è´¥çš„æ–‡ä»¶:")
        for file in error_files:
            print(f"  - {file}")
    
    if success_count > 0:
        print(f"\næˆåŠŸç”Ÿæˆçš„æ–‡ä»¶ä¿å­˜åœ¨: {target_dir}/")

if __name__ == "__main__":
    batch_predict() 